{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs.py\n",
    "\n",
    "# S3 Bucket and Folder Configuration\n",
    "BUCKET = \"cubix-chicago-taxi-bb\"\n",
    "\n",
    "# Raw Data Folders\n",
    "RAW_WEATHER_FOLDER = \"raw_data/to_processed/weather_data/\"\n",
    "RAW_TAXI_TRIPS_FOLDER = \"raw_data/to_processed/taxi_data/\"\n",
    "\n",
    "# Processed Data Folders\n",
    "TARGET_TAXI_TRIPS_FOLDER = \"raw_data/processed/taxi_data/\"\n",
    "TARGET_WEATHER_FOLDER = \"raw_data/processed/weather_data/\"\n",
    "\n",
    "# Transformed Data Folders\n",
    "TRANSFORMED_TAXI_TRIPS_FOLDER = \"transformed_data/taxi_trips/\"\n",
    "TRANSFORMED_WEATHER_FOLDER = \"transformed_data/weather/\"\n",
    "\n",
    "# Master Data Folders and Files\n",
    "PAYMENT_TYPE_MASTER_FOLDER = \"transformed_data/payment_type/\"\n",
    "COMPANY_MASTER_FOLDER = \"transformed_data/company/\"\n",
    "\n",
    "# Master file names\n",
    "PAYMENT_TYPE_MASTER_FILE = \"payment_type_master.csv\"\n",
    "COMPANY_MASTER_FILE = \"company_master.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions.py\n",
    "\n",
    "from io import StringIO\n",
    "import json\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "def taxi_trips_transformations(taxi_trips: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Perform transformations on the taxi data.\n",
    "    \n",
    "    1. Drop selected columns\n",
    "    2. Drop NULL values accross all columns.\n",
    "    3. Rename columns.\n",
    "    4. Create \"datetime_for_weather\" column.\n",
    "\n",
    "    :param taxi_trips:  The DataFrame holding the daily taxi trips\n",
    "    :raises TypeError:  When taxi_trips parameter is not a valid pandas DataFrame.\n",
    "    :return:            Transformed, cleaned taxi_trips DataFrame. \n",
    "    \"\"\"\n",
    "    if not isinstance(taxi_trips, pd.DataFrame):\n",
    "        raise TypeError(\"taxi_trips is not a valid pandas DataFrame.\")\n",
    "\n",
    "    taxi_trips.drop([\"pickup_census_tract\", \"dropoff_census_tract\", \n",
    "                     \"pickup_centroid_location\", \"dropoff_centroid_location\"], axis=1, inplace=True)\n",
    "    taxi_trips.dropna(inplace=True)\n",
    "    taxi_trips.rename(columns={\"pickup_community_area\": \"pickup_community_area_id\",\n",
    "                                \"dropoff_community_area\": \"dropoff_community_area_id\"}, inplace=True)\n",
    "    taxi_trips[\"datetime_for_weather\"] = pd.to_datetime(taxi_trips[\"trip_start_timestamp\"]).dt.floor(\"H\")\n",
    "\n",
    "    return taxi_trips\n",
    "    \n",
    "   \n",
    "def update_taxi_trips_with_master_data(taxi_trips: pd.DataFrame, payment_type_master: pd.DataFrame, company_master: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Update the taxi_trips DataFrame with the company_master and payment_type_master ids, and delete the string columns.\n",
    "\n",
    "    :param taxi_trips:              The DataFrame with the daily taxi trips.\n",
    "    :param payment_type_master:     The payment type master table.\n",
    "    :param company_master:          The company master table.\n",
    "    :return:                        The taxi trips data, with only payment_type_id and company_id, without company or\n",
    "                                    payment_type values.\n",
    "    \"\"\"\n",
    "    taxi_trips_id = taxi_trips.merge(payment_type_master, on=\"payment_type\")\n",
    "    taxi_trips_id = taxi_trips_id.merge(company_master, on=\"company\")\n",
    "    taxi_trips_id.drop([\"payment_type\", \"company\"], axis=1, inplace=True)\n",
    "\n",
    "    return taxi_trips_id\n",
    "\n",
    "   \n",
    "def update_master(taxi_trips: pd.DataFrame, master: pd.DataFrame, id_column: str, value_column: str) -> pd.DataFrame:\n",
    "    \"\"\"Extend the master DataFrame with new values if there are any.\n",
    "\n",
    "    :param taxi_trips:      DataFrame with the daily taxi trips.\n",
    "    :param master:          DataFrame with the master data (company, payment_type).\n",
    "    :param id_column:       The id column of the master DataFrame.\n",
    "    :param value_column:    Name of the column in master_df containing the values.\n",
    "    :return:                The updated master data, if new values are in the taxi data, they will be loaded to it.\n",
    "    \"\"\"\n",
    "    max_id = master[id_column].max()\n",
    "\n",
    "    new_values_list = list(set(taxi_trips[value_column].values) - set(master[value_column].values))\n",
    "    new_values_df = pd.DataFrame({\n",
    "        id_column: range(max_id + 1, max_id + len(new_values_list) + 1),\n",
    "        value_column: new_values_list\n",
    "    })\n",
    "    updated_master = pd.concat([master, new_values_df], ignore_index=True)\n",
    "    \n",
    "    new_values_df = pd.DataFrame({\n",
    "        id_column: range(max_id + 1, max_id + len(new_values_list) + 1),\n",
    "        value_column: new_values_list\n",
    "    })\n",
    "    updated_master = pd.concat([master, new_values_df], ignore_index=True)\n",
    "\n",
    "    return updated_master    \n",
    "\n",
    "\n",
    "def transform_weather_data(weather_data: json) -> pd.DataFrame:\n",
    "    \"\"\"Select and transform weather data.\n",
    "\n",
    "    :param weather_data:    The daily weather data from the Open Meteo API.\n",
    "    :return:                Transformed weather data.  \n",
    "    \"\"\"\n",
    "    weather_data_filtered = {\n",
    "            \"datetime\": weather_data[\"hourly\"][\"time\"],\n",
    "            \"tempretaure\": weather_data[\"hourly\"][\"temperature_2m\"],\n",
    "            \"wind_speed\": weather_data[\"hourly\"][\"wind_speed_10m\"],\n",
    "            \"rain\": weather_data[\"hourly\"][\"rain\"],\n",
    "            \"precipitation\": weather_data[\"hourly\"][\"precipitation\"],\n",
    "        }\n",
    "\n",
    "    weather_df = pd.DataFrame(weather_data_filtered)\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"datetime\"])\n",
    "\n",
    "    return weather_df\n",
    "\n",
    "\n",
    "def read_csv_from_s3(bucket: str, path: str, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Downloads a csv file from an S3 bucket.\n",
    "\n",
    "    :param bucket:      The bucket where the file is.\n",
    "    :param path:        Path to the file.\n",
    "    :param filename:    Name of the file to read.\n",
    "    :return:            A DataFrame created from the csv file.\n",
    "    \"\"\"\n",
    "    full_path = f\"{path}{filename}\"\n",
    "    \n",
    "    object = s3.get_object(Bucket=bucket, Key=full_path)\n",
    "    object = object[\"Body\"].read().decode(\"utf-8\")\n",
    "    output_df = pd.read_csv(StringIO(object))\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "\n",
    "def read_json_from_s3(bucket: str, filename: str) -> Union[List[Dict], Dict]:\n",
    "    \"\"\"Downloads a json file from an S3 bucket.\n",
    "\n",
    "    :param s3:          S3 client.\n",
    "    :param bucket:      The bucket where the file is.\n",
    "    :param filename:    Name of the file to read.\n",
    "    :return:            A list of dictionaries or a dictionary (taxi or weather data).\n",
    "    \"\"\"\n",
    "    response = s3.get_object(Bucket=bucket, Key=filename)\n",
    "    content = response[\"Body\"]\n",
    "    taxi_trips_data_json = json.loads(content.read())\n",
    "    \n",
    "    return taxi_trips_data_json\n",
    "    \n",
    "    \n",
    "def upload_dataframe_to_s3(dataframe: pd.DataFrame, bucket: str, path: str):\n",
    "    \"\"\"Uploads a dataframe to the specified S3 path.\n",
    "\n",
    "    :param s3:          S3 client.\n",
    "    :param dataframe:   The DataFrame to be uploaded.\n",
    "    :param bucket:      Name of the S3 bucket where the file will be stored.\n",
    "    :param path:        Path within the bucket to upload the file.\n",
    "    \"\"\"\n",
    "    buffer = StringIO()\n",
    "    dataframe.to_csv(buffer, index=False)\n",
    "    df_content = buffer.getvalue()\n",
    "    s3.put_object(Bucket=bucket, Key=path, Body=df_content)\n",
    "\n",
    " \n",
    "def upload_master_data_to_s3(bucket: str, path: str, file_type: str, dataframe: pd.DataFrame):\n",
    "    \"\"\"Uploads master data (payment_type or company) to S3. Copies the previous version and creates the new one.\n",
    "\n",
    "    :param s3:          S3 client.\n",
    "    :param bucket:      Name of the S3 bucket where the file will be stored.\n",
    "    :param path:        Path within the bucket to upload the file.\n",
    "    :param file_type:   Either \"company\" or \"payment_type\".\n",
    "    :param dataframe:   The DataFrame to be uploaded.\n",
    "    :raises ValueError: Raised when file_type is not \"company\" or \"payment_type\".\n",
    "    \"\"\"\n",
    "    if not file_type in [\"company\", \"payment_type\"]:\n",
    "        raise ValueError(\"file_type must be either 'company' or 'payment_type'.\")\n",
    "\n",
    "    master_file_path = f\"{path}{file_type}_master.csv\"\n",
    "    previous_master_file_path = f\"transformed_data/master_table_previous_version/{file_type}_master_previous_version.csv\"\n",
    "    \n",
    "    s3.copy_object(\n",
    "        Bucket=bucket,\n",
    "        CopySource={\"Bucket\": bucket, \"Key\": master_file_path},\n",
    "        Key=previous_master_file_path\n",
    "    )\n",
    "    \n",
    "    upload_dataframe_to_s3(bucket=bucket, dataframe=dataframe, path=master_file_path)\n",
    "    \n",
    "def move_file_on_s3(bucket: str, source_key: str, target_key: str):\n",
    "    \"\"\"\n",
    "    Moves a file within S3 by copying it to a new location and deleting the original.\n",
    "\n",
    "    :param bucket:     Name of the S3 bucket.\n",
    "    :param source_key: Current path (including filename) of the file.\n",
    "    :param target_key: New path (including filename) where the file will be moved.\n",
    "    \"\"\"\n",
    "    s3.copy_object(\n",
    "        Bucket=bucket,\n",
    "        CopySource={\"Bucket\": bucket, \"Key\": source_key},\n",
    "        Key=target_key\n",
    "    )\n",
    "    \n",
    "    s3.delete_object(Bucket=bucket, Key=source_key)\n",
    "    print(f\"File moved from s3://{bucket}/{source_key} to s3://{bucket}/{target_key}.\")\n",
    "\n",
    "\n",
    "def upload_and_move_file_on_s3(\n",
    "        dataframe: pd.DataFrame, \n",
    "        datetime_col: str, \n",
    "        bucket: str, \n",
    "        file_type: str, \n",
    "        filename: str,\n",
    "        source_path: str,\n",
    "        target_path_raw: str,\n",
    "        target_path_transformed: str\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Orchestrates uploading a DataFrame to S3 and moving a file within S3.\n",
    "\n",
    "    :param dataframe:               The DataFrame to upload.\n",
    "    :param datetime_col:            Datetime column name, used to derive the date for the filename.\n",
    "    :param bucket:                  Name of the S3 bucket.\n",
    "    :param file_type:               \"weather\" or \"taxi\".\n",
    "    :param filename:                Name of the file to be moved.\n",
    "    :param source_path:             Source path within the bucket.\n",
    "    :param target_path_raw:         Target path within the bucket where the raw data is copied.\n",
    "    :param\n",
    "    \"\"\" \n",
    "    formatted_date = dataframe[datetime_col].iloc[0].strftime(\"%Y-%m-%d\")\n",
    "    transformed_path = f\"{target_path_transformed}{file_type}_{formatted_date}.csv\"\n",
    "    \n",
    "    upload_dataframe_to_s3(bucket=bucket, dataframe=dataframe, path=transformed_path)\n",
    "\n",
    "    source_key = f\"{source_path}{filename}\"\n",
    "    target_key = f\"{target_path_raw}{filename}\"\n",
    "    move_file_on_s3(bucket, source_key, target_key)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_function.py\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "from configs import (\n",
    "    BUCKET,\n",
    "    RAW_TAXI_TRIPS_FOLDER,\n",
    "    RAW_WEATHER_FOLDER,\n",
    "    TARGET_TAXI_TRIPS_FOLDER,\n",
    "    TARGET_WEATHER_FOLDER,\n",
    "    TRANSFORMED_TAXI_TRIPS_FOLDER,\n",
    "    TRANSFORMED_WEATHER_FOLDER,\n",
    "    PAYMENT_TYPE_MASTER_FOLDER,\n",
    "    COMPANY_MASTER_FOLDER,\n",
    "    PAYMENT_TYPE_MASTER_FILE,\n",
    "    COMPANY_MASTER_FILE,\n",
    ")\n",
    "from functions import (\n",
    "    taxi_trips_transformations,\n",
    "    update_taxi_trips_with_master_data,\n",
    "    update_master,\n",
    "    transform_weather_data,\n",
    "    read_csv_from_s3,\n",
    "    read_json_from_s3,\n",
    "    upload_master_data_to_s3,\n",
    "    upload_and_move_file_on_s3,\n",
    ")\n",
    "\n",
    "\n",
    "def process_taxi_data(s3: boto3.client, payment_type_master: pd.DataFrame, company_master: pd.DataFrame):\n",
    "    \"\"\"Process and transform taxi trip data.\n",
    "\n",
    "    1. Check the raw taxi trips folder for new JSON files.\n",
    "    2. Read and transform them.\n",
    "    3. Update the Company Master and Payment Type Master mapping tables.\n",
    "    4. Update the transformed taxi data with Company and Payment Type ids (change string values to ids).\n",
    "    5. Move the raw files from the \"to_processed\" to the \"processed\" folder, and upload the cleaned and transformed DataFrame.\n",
    "    6. Update the Company Master and Payment Type Master tables.\n",
    "\n",
    "    :param s3:                      S3 client.\n",
    "    :param payment_type_master:     Payment Type Master DataFrame.\n",
    "    :param company_master:          Company Master DataFrame.\n",
    "    \"\"\"\n",
    "    for file in s3.list_objects(Bucket=BUCKET, Prefix=RAW_TAXI_TRIPS_FOLDER)[\"Contents\"]:\n",
    "        taxi_trip_key = file[\"Key\"]\n",
    "        \n",
    "        if taxi_trip_key.split(\"/\")[-1].strip() != \"\":\n",
    "            if taxi_trip_key.split(\".\")[1] == \"json\":\n",
    "                \n",
    "                filename = taxi_trip_key.split(\"/\")[-1]               \n",
    "                taxi_trips_data_json = read_json_from_s3(BUCKET, taxi_trip_key)\n",
    "                \n",
    "                taxi_trips_data_raw = pd.DataFrame(taxi_trips_data_json)\n",
    "                taxi_trips_transformed = taxi_trips_transformations(taxi_trips_data_raw)\n",
    "      \n",
    "                company_master_updated = update_master(taxi_trips_transformed, company_master, \"company_id\", \"company\")\n",
    "                payment_type_master_updated = update_master(taxi_trips_transformed, payment_type_master, \"payment_type_id\", \"payment_type\")\n",
    "                \n",
    "                taxi_trips = update_taxi_trips_with_master_data(taxi_trips_transformed, payment_type_master_updated, company_master_updated)\n",
    "                \n",
    "                upload_and_move_file_on_s3(\n",
    "                        dataframe=taxi_trips, \n",
    "                        datetime_col=\"datetime_for_weather\", \n",
    "                        bucket=BUCKET, \n",
    "                        file_type=\"taxi\", \n",
    "                        filename=filename,\n",
    "                        source_path=RAW_TAXI_TRIPS_FOLDER,\n",
    "                        target_path_raw=TARGET_TAXI_TRIPS_FOLDER,\n",
    "                        target_path_transformed=TRANSFORMED_TAXI_TRIPS_FOLDER\n",
    "                    )\n",
    "                print(f\"Taxi trips file {filename} uploaded and moved.\")\n",
    "                \n",
    "                upload_master_data_to_s3(bucket=BUCKET, path=PAYMENT_TYPE_MASTER_FOLDER, file_type=\"payment_type\", dataframe=payment_type_master_updated)\n",
    "                print(\"Payment Type Master has been updated.\")\n",
    "                upload_master_data_to_s3(bucket=BUCKET, path=COMPANY_MASTER_FOLDER, file_type=\"company\", dataframe=company_master_updated)\n",
    "                print(\"Company Master has been updated.\")\n",
    "\n",
    "\n",
    "def process_weather_data(s3: boto3.client):\n",
    "    \"\"\"Process and transform weather data.\n",
    "\n",
    "    1. Check the raw weather folder for new JSON files.\n",
    "    2. Read and transform them.\n",
    "    3. Move the raw files from the \"to_processed\" to the \"processed\" folder, and upload the cleaned and transformed DataFrame.\n",
    "\n",
    "    :param s3:  S3 client.\n",
    "    \"\"\"\n",
    "    for file in s3.list_objects(Bucket=BUCKET, Prefix=RAW_WEATHER_FOLDER)[\"Contents\"]:\n",
    "        weather_key = file[\"Key\"]\n",
    "        \n",
    "        if weather_key.split(\"/\")[-1].strip() != \"\":\n",
    "            if weather_key.split(\".\")[1] == \"json\":\n",
    "                \n",
    "                filename = weather_key.split(\"/\")[-1]\n",
    "                weather_data_json = read_json_from_s3(BUCKET, weather_key)\n",
    "                weather_data = transform_weather_data(weather_data_json)\n",
    "                \n",
    "                upload_and_move_file_on_s3(\n",
    "                        dataframe=weather_data, \n",
    "                        datetime_col=\"datetime\", \n",
    "                        bucket=BUCKET, \n",
    "                        file_type=\"weather\", \n",
    "                        filename=filename,\n",
    "                        source_path=RAW_WEATHER_FOLDER,\n",
    "                        target_path_raw=TARGET_WEATHER_FOLDER,\n",
    "                        target_path_transformed=TRANSFORMED_WEATHER_FOLDER\n",
    "                    )\n",
    "            print(f\"Weather file {filename} uploaded and moved.\")\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "\n",
    "    payment_type_master = read_csv_from_s3(bucket=BUCKET, path=PAYMENT_TYPE_MASTER_FOLDER, filename=PAYMENT_TYPE_MASTER_FILE)\n",
    "    company_master = read_csv_from_s3(bucket=BUCKET, path=COMPANY_MASTER_FOLDER, filename=COMPANY_MASTER_FILE)\n",
    "\n",
    "    process_taxi_data(s3, payment_type_master, company_master)\n",
    "    process_weather_data(s3)\n",
    "\n",
    "    print(\"All files have been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "from config import (\n",
    "    BUCKET,\n",
    "    RAW_TAXI_TRIPS_FOLDER,\n",
    "    RAW_WEATHER_FOLDER,\n",
    "    TARGET_TAXI_TRIPS_FOLDER,\n",
    "    TARGET_WEATHER_FOLDER,\n",
    "    TRANSFORMED_TAXI_TRIPS_FOLDER,\n",
    "    TRANSFORMED_WEATHER_FOLDER,\n",
    "    PAYMENT_TYPE_MASTER_FOLDER,\n",
    "    COMPANY_MASTER_FOLDER,\n",
    "    PAYMENT_TYPE_MASTER_FILE,\n",
    "    COMPANY_MASTER_FILE,\n",
    ")\n",
    "\n",
    "from functions import (\n",
    "    taxi_trips_transformations,\n",
    "    update_taxi_trips_with_master_data,\n",
    "    update_master,\n",
    "    transform_weather_data,\n",
    "    read_csv_from_s3,\n",
    "    read_json_from_s3,\n",
    "    upload_master_data_to_s3,\n",
    "    upload_and_move_file_on_s3\n",
    ")\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    payment_type_master = read_csv_from_s3(bucket=BUCKET, path=PAYMENT_TYPE_MASTER_FOLDER, filename=PAYMENT_TYPE_MASTER_FILE)\n",
    "    company_master = read_csv_from_s3(bucket=BUCKET, path=COMPANY_MASTER_FOLDER, filename=COMPANY_MASTER_FILE)\n",
    "\n",
    "    # TAXI DATA TRANSFORMATION AND LOADING\n",
    "    for file in s3.list_objects(Bucket=BUCKET, Prefix=RAW_TAXI_TRIPS_FOLDER)[\"Contents\"]:\n",
    "        taxi_trip_key = file[\"Key\"]\n",
    "        \n",
    "        if taxi_trip_key.split(\"/\")[-1].strip() != \"\":\n",
    "            if taxi_trip_key.split(\".\")[1] == \"json\":\n",
    "                \n",
    "                filename = taxi_trip_key.split(\"/\")[-1]\n",
    "                \n",
    "                taxi_trips_data_json = read_json_from_s3(BUCKET, taxi_trip_key)\n",
    "                \n",
    "                taxi_trips_data_raw = pd.DataFrame(taxi_trips_data_json)\n",
    "                taxi_trips_transformed = taxi_trips_transformations(taxi_trips_data_raw)\n",
    "      \n",
    "                company_master_updated = update_master(taxi_trips_transformed, company_master, \"company_id\", \"company\")\n",
    "                payment_type_master_updated = update_master(taxi_trips_transformed, payment_type_master, \"payment_type_id\", \"payment_type\")\n",
    "                \n",
    "                taxi_trips = update_taxi_trips_with_master_data(taxi_trips_transformed, payment_type_master_updated, company_master_updated)\n",
    "                \n",
    "                upload_and_move_file_on_s3(\n",
    "                        dataframe=taxi_trips, \n",
    "                        datetime_col=\"datetime_for_weather\", \n",
    "                        bucket=BUCKET, \n",
    "                        file_type=\"taxi\", \n",
    "                        filename=filename,\n",
    "                        source_path=RAW_TAXI_TRIPS_FOLDER,\n",
    "                        target_path_raw=TARGET_TAXI_TRIPS_FOLDER,\n",
    "                        target_path_transformed=TRANSFORMED_TAXI_TRIPS_FOLDER\n",
    "                    )\n",
    "                print(\"taxi_trips is uploaded and moved.\")\n",
    "                \n",
    "                upload_master_data_to_s3(bucket=BUCKET, path=PAYMENT_TYPE_MASTER_FOLDER, file_type=\"payment_type\", dataframe=payment_type_master_updated)\n",
    "                print(\"payment_type_master has been updated.\")\n",
    "                upload_master_data_to_s3(bucket=BUCKET, path=COMPANY_MASTER_FOLDER, file_type=\"company\", dataframe=company_master_updated)\n",
    "                print(\"company_master has been updated.\")\n",
    "\n",
    "    # WEATHER DATA TRANSFORMATION AND LOADING\n",
    "    for file in s3.list_objects(Bucket=BUCKET, Prefix=RAW_WEATHER_FOLDER)[\"Contents\"]:\n",
    "        weather_key = file[\"Key\"]\n",
    "        \n",
    "        if weather_key.split(\"/\")[-1].strip() != \"\":\n",
    "            if weather_key.split(\".\")[1] == \"json\":\n",
    "                \n",
    "                filename = weather_key.split(\"/\")[-1]\n",
    "                \n",
    "                weather_data_json = read_json_from_s3(BUCKET, weather_key)\n",
    "                \n",
    "                weather_data = transform_weather_data(weather_data_json)\n",
    "                \n",
    "                upload_and_move_file_on_s3(\n",
    "                        dataframe=weather_data, \n",
    "                        datetime_col=\"datetime\", \n",
    "                        bucket=BUCKET, \n",
    "                        file_type=\"weather\", \n",
    "                        filename=filename,\n",
    "                        source_path=RAW_WEATHER_FOLDER,\n",
    "                        target_path_raw=TARGET_WEATHER_FOLDER,\n",
    "                        target_path_transformed=TRANSFORMED_WEATHER_FOLDER\n",
    "                    )\n",
    "                print(\"weather is uploaded and moved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
