{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_trips_transformations(taxi_trips: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform transformations on the taxi_trips DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ---------- \n",
    "    taxi_trips: pd.DataFrame\n",
    "        The DataFrame containing the taxi trips data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The transformed DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(taxi_trips, pd.DataFrame):\n",
    "        raise TypeError(\"taxi_trips should be a DataFrame\")\n",
    "\n",
    "    taxi_trips.drop([\"pickup_census_tract\", \"dropoff_census_tract\", \n",
    "                     \"pickup_centroid_location\", \"dropoff_centroid_location\"], axis=1, inplace=True)\n",
    "\n",
    "    taxi_trips.dropna(inplace=True)\n",
    "\n",
    "    taxi_trips.rename(columns={\"pickup_community_area\": \"pickup_community_area_id\",\n",
    "                               \"dropoff_community_area\": \"dropoff_community_area_id\"}, inplace=True)\n",
    "\n",
    "    taxi_trips[\"datetime_for_weather\"] = pd.to_datetime(taxi_trips[\"trip_start_timestamp\"]).dt.floor(\"h\")\n",
    "\n",
    "    return taxi_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_master(taxi_trips: pd.DataFrame, master: pd.DataFrame, id_column: str, value_column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Update the master DataFrame with new companies from the taxi_trips DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    taxi_trips: pd.DataFrame\n",
    "        The DataFrame containing the taxi trips data\n",
    "    master: pd.DataFrame\n",
    "        The DataFrame containing the master data\n",
    "    id_column: str\n",
    "        The id column of the master DataFrame.\n",
    "    value_column: str\n",
    "        The name of the column in master_df containing the values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The updated master DataFrame\n",
    "    \"\"\"\n",
    "    max_id = master[id_column].max()\n",
    "\n",
    "    new_values_list = list(set(taxi_trips[value_column].values) - set(master[value_column].values))\n",
    "    new_values_df = pd.DataFrame({\n",
    "        id_column: range(max_id + 1, max_id + 1 + len(new_values_list)),\n",
    "        value_column: new_values_list\n",
    "    })\n",
    "\n",
    "    updated_master = pd.concat([master, new_values_df], ignore_index=True)\n",
    "\n",
    "    return updated_master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_taxi_trips_with_master_data(taxi_trips: pd.DataFrame, payment_type_master: pd.DataFrame, company_master: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Update the taxi_trips DataFrame with the payment_type_master and company_master ids\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    taxi_trips: pd.DataFrame\n",
    "        The DataFrame containing the taxi trips data\n",
    "    payment_type_master: pd.DataFrame\n",
    "        The DataFrame containing the payment_type master table\n",
    "    company_master: pd.DataFrame\n",
    "        The DataFrame containing the company master table\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The updated taxi_trips DataFrame with the payment_type and company ids, without the string values\n",
    "    '''\n",
    "    taxi_trips_id  = taxi_trips.merge(payment_type_master, on=\"payment_type\")\n",
    "    taxi_trips_id  = taxi_trips_id.merge(company_master, on=\"company\")\n",
    "    \n",
    "    taxi_trips_id.drop([\"payment_type\", \"company\"], axis=1, inplace=True)\n",
    "    \n",
    "    return taxi_trips_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_weather_data(weather_data: json) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform transformations on the weather data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    weather_data: dict\n",
    "        The daily weather data from the Open Meteo API\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The transformed weather data DataFrame\n",
    "    \"\"\"\n",
    "    weather_data_filtered = {\n",
    "        \"datetime\": weather_data['hourly']['time'],\n",
    "        \"temperature\": weather_data['hourly']['temperature_2m'],\n",
    "        \"wind_speed\": weather_data['hourly']['wind_speed_10m'],\n",
    "        \"rain\": weather_data['hourly']['rain'],\n",
    "        \"precipitation\": weather_data['hourly']['precipitation']\n",
    "    }\n",
    "\n",
    "    weather_df = pd.DataFrame(weather_data_filtered)\n",
    "\n",
    "    weather_df['datetime'] = pd.to_datetime(weather_df['datetime'])\n",
    "\n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_from_s3(bucket: str, path: str, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a CSV file from S3 and return it as a DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket: str\n",
    "        The name of the S3 bucket\n",
    "    path: str\n",
    "        The path to the CSV file in the S3 bucket\n",
    "    filename: str\n",
    "        The name of the CSV file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame containing the CSV data\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    obj = s3.get_object(Bucket=bucket, Key=f\"{path}{filename}\")\n",
    "\n",
    "    output_df = pd.read_csv(StringIO(obj['Body'].read().decode('utf-8')))\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataframe_to_s3(bucket: str, path: str, dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Upload a DataFrame to S3 as a CSV file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket: str\n",
    "        The name of the S3 bucket\n",
    "    path: str\n",
    "        The path to upload the CSV file in the S3 bucket\n",
    "    filename: str\n",
    "        The name of the CSV file\n",
    "    dataframe: pd.DataFrame\n",
    "        The DataFrame to be uploaded\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    buffer = StringIO()\n",
    "    dataframe.to_csv(buffer, index=False)\n",
    "    df_content = buffer.getvalue()\n",
    "    s3.put_object(Bucket=bucket, Key=path, Body=df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_master_table_to_s3(bucket: str, path: str, file_type: str, dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Uploads master data (payment type or company) to S3. Copies previous version and creates new one\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket: str\n",
    "        Name of the S3 bucket, where we want to store the files\n",
    "    path: str\n",
    "        Path within the bucket to upload the file\n",
    "    file_type: str\n",
    "        Either \"company\" or \"payment_type\"\n",
    "    dataframe: pd.Dataframe\n",
    "        The dataframe to be uploaded\n",
    "        \n",
    "    Returns\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    master_filepath = f\"{path}{file_type}_master.csv\"\n",
    "    previous_master_filepath = f\"transformed_data/master_table_previous_versions/{file_type}_master_previous_version.csv\"\n",
    "\n",
    "    s3.copy_object(\n",
    "        Bucket=bucket, \n",
    "        CopySource={'Bucket': bucket, 'Key': master_filepath},\n",
    "        Key=previous_master_filepath)\n",
    "\n",
    "    upload_dataframe_to_s3(bucket, master_filepath, dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_and_move_file_on_s3(\n",
    "    dataframe: pd.DataFrame, \n",
    "    datetime_col: str, \n",
    "    bucket: str, \n",
    "    file_type: str,\n",
    "    filename: str,\n",
    "    source_path: str,\n",
    "    target_path_raw: str,\n",
    "    target_path_transformed: str) -> None:\n",
    "    \"\"\"\n",
    "    Uploads a file to S3 and moves it from the source path to the target path\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: pd.DataFrame\n",
    "        The DataFrame to be uploaded\n",
    "    datetime_col: str\n",
    "        The name of the column containing the datetime\n",
    "    bucket: str\n",
    "        The name of the S3 bucket\n",
    "    file_type: str\n",
    "        The type of the file (e.g., \"weather\", \"taxi\")\n",
    "    filename: str\n",
    "        The name of the file\n",
    "    source_path: str\n",
    "        The path in the S3 bucket where the file is currently located\n",
    "    target_path_raw: str\n",
    "        The path in the S3 bucket where the file should be moved after processing\n",
    "    target_path_transformed: str\n",
    "        The path in the S3 bucket where the file should be uploaded after processing\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    formatted_date = dataframe[datetime_col].iloc[0].strftime(\"%Y-%m-%d\")\n",
    "    new_path_with_filename = f\"{target_path_transformed}{file_type}_{formatted_date}.csv\"\n",
    "\n",
    "    upload_dataframe_to_s3(bucket, new_path_with_filename, dataframe)\n",
    "\n",
    "    s3.copy_object(\n",
    "        Bucket=bucket,\n",
    "        CopySource={'Bucket': bucket, 'Key': f\"{source_path}{filename}\"},\n",
    "        Key=f\"{target_path_raw}{filename}\")\n",
    "\n",
    "    s3.delete_object(Bucket=bucket, Key=f\"{source_path}{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_from_s3(bucket: str, path: str) -> json:\n",
    "    \"\"\"\n",
    "    Read a JSON file from S3 and return it as a dictionary\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    bucket: str\n",
    "        The name of the S3 bucket\n",
    "    path: str\n",
    "        The path to the json file to read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The json file content\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.get_object(Bucket=bucket, Key=path)\n",
    "    content = response[\"Body\"]\n",
    "    return json.loads(content.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# MAIN FUNCTION\n",
    "#\n",
    "#\n",
    "def lambda_handler(event, context):\n",
    "    s3 = boto3.client('s3')\n",
    "    bucket = 'cubix-chicago-taxi-34'\n",
    "\n",
    "    raw_weather_folder = 'raw_data/to_processed/weather_data/'\n",
    "    raw_taxi_trips_folder = 'raw_data/to_processed/taxi_data/'\n",
    "\n",
    "    target_taxi_trips_folder = 'raw_data/processed/taxi_data/'\n",
    "    target_wet_weather_folder = 'raw_data/processed/weather_data/'\n",
    "\n",
    "    transformed_taxi_trips_folder = 'transformed_data/taxi_trips/'\n",
    "    transformed_weather_folder = 'transformed_data/weather/'\n",
    "    \n",
    "    payment_type_master_folder = 'transformed_data/payment_type/'\n",
    "    company_master_folder = 'transformed_data/company/'\n",
    "\n",
    "    payment_type_master_filename = 'payment_type_master.csv'\n",
    "    company_master_filename = 'company_master.csv'\n",
    "\n",
    "    payment_type_master = read_csv_from_s3(bucket, payment_type_master_folder, payment_type_master_filename)\n",
    "    company_master = read_csv_from_s3(bucket, company_master_folder, company_master_filename)\n",
    "\n",
    "    # TAXI TRIPS DATA TRANSFORMATION AND LOADING\n",
    "    for file in s3.list_objects_v2(Bucket=bucket, Prefix=raw_taxi_trips_folder)['Contents']:\n",
    "        file_key = file['Key']\n",
    "\n",
    "        if(file_key.split('/'))[-1].strip() != \"\":\n",
    "            if(file_key.split('.')[1] == \"json\"):\n",
    "                filename = file_key.split('/')[-1]\n",
    "\n",
    "                taxi_trips_data_json = read_json_from_s3(bucket, file_key)\n",
    "\n",
    "                taxi_trips_data_raw = pd.DataFrame(taxi_trips_data_json)\n",
    "                taxi_trips_transformed = taxi_trips_transformations(taxi_trips_data_raw)\n",
    "\n",
    "                company_master_updated = update_master(taxi_trips_transformed, company_master, \"company_id\", \"company\")\n",
    "                payment_type_master_updated = update_master(taxi_trips_transformed, payment_type_master, \"payment_type_id\", \"payment_type\")\n",
    "\n",
    "                taxi_trips_updated = update_taxi_trips_with_master_data(taxi_trips_transformed, payment_type_master_updated, company_master_updated)\n",
    "\n",
    "                upload_and_move_file_on_s3(\n",
    "                    taxi_trips_updated,\n",
    "                    \"datetime_for_weather\",\n",
    "                    bucket,\n",
    "                    \"taxi\",\n",
    "                    filename,\n",
    "                    raw_taxi_trips_folder,\n",
    "                    target_taxi_trips_folder,\n",
    "                    transformed_taxi_trips_folder\n",
    "                )\n",
    "                print(\"taxi trips is uploaded and moved\")\n",
    "\n",
    "                upload_master_table_to_s3(bucket, payment_type_master_folder, \"payment_type\", payment_type_master_updated)\n",
    "                print(\"Payment type master updated\")\n",
    "\n",
    "                upload_master_table_to_s3(bucket, company_master_folder, \"company\", company_master_updated)\n",
    "                print(\"Company master updated\")\n",
    "\n",
    "    # WEATHER DATA TRANSFORMATION AND LOADING\n",
    "    for file in s3.list_objects_v2(Bucket=bucket, Prefix=raw_weather_folder)['Contents']:\n",
    "        file_key = file['Key']\n",
    "\n",
    "        if(file_key.split('/'))[-1].strip() != \"\":\n",
    "            if(file_key.split('.')[1] == \"json\"):\n",
    "                filename = file_key.split('/')[-1]\n",
    "\n",
    "                weather_data_json = read_json_from_s3(bucket, file_key)\n",
    "                weather_data = transform_weather_data(weather_data_json)\n",
    "                \n",
    "                upload_and_move_file_on_s3(\n",
    "                    weather_data,\n",
    "                    \"datetime\",\n",
    "                    bucket,\n",
    "                    \"weather\",\n",
    "                    filename,\n",
    "                    raw_weather_folder,\n",
    "                    target_wet_weather_folder,\n",
    "                    transformed_weather_folder\n",
    "                )\n",
    "                print(\"weather data is uploaded and moved\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
